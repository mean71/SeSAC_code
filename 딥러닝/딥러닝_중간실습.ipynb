{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\mean71\\appdata\\roaming\\python\\python311\\site-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\mean71\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (2.1.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mean71\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mean71\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mean71\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.860133409500122\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "0.0\n",
            "32\n",
            "2.860133409500122\n",
            "2.849282741546631\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "0.0\n",
            "51\n",
            "2.849282741546631\n",
            "Epoch 1/200, Loss: 2.85471, Accuracy: 0.00000\n",
            "2.8399534225463867\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "0.0\n",
            "32\n",
            "2.834181070327759\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "0.0\n",
            "51\n",
            "Epoch 2/200, Loss: 2.83707, Accuracy: 0.00000\n",
            "2.822571039199829\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "0.0\n",
            "32\n",
            "2.8142497539520264\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "0.0\n",
            "51\n",
            "Epoch 3/200, Loss: 2.81841, Accuracy: 0.00000\n",
            "2.802816152572632\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "0.0\n",
            "32\n",
            "2.7966957092285156\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "0.0\n",
            "51\n",
            "Epoch 4/200, Loss: 2.79976, Accuracy: 0.00000\n",
            "2.784008741378784\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "0.0\n",
            "32\n",
            "2.773848533630371\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "0.0\n",
            "51\n",
            "Epoch 5/200, Loss: 2.77893, Accuracy: 0.00000\n",
            "2.7634575366973877\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "0.0\n",
            "32\n",
            "2.7502870559692383\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "0.0\n",
            "51\n",
            "Epoch 6/200, Loss: 2.75687, Accuracy: 0.00000\n",
            "2.7383170127868652\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "0.0\n",
            "32\n",
            "2.729891777038574\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "2.0\n",
            "51\n",
            "Epoch 7/200, Loss: 2.73410, Accuracy: 0.03922\n",
            "2.715698480606079\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "6.0\n",
            "32\n",
            "2.6994667053222656\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "21.0\n",
            "51\n",
            "Epoch 8/200, Loss: 2.70758, Accuracy: 0.41176\n",
            "2.688317060470581\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "31.0\n",
            "32\n",
            "2.670206308364868\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "50.0\n",
            "51\n",
            "Epoch 9/200, Loss: 2.67926, Accuracy: 0.98039\n",
            "2.6573784351348877\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.6381680965423584\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 10/200, Loss: 2.64777, Accuracy: 1.00000\n",
            "2.6215450763702393\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.603818416595459\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 11/200, Loss: 2.61268, Accuracy: 1.00000\n",
            "2.5821564197540283\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.5621347427368164\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 12/200, Loss: 2.57215, Accuracy: 1.00000\n",
            "2.5380117893218994\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.513745069503784\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 13/200, Loss: 2.52588, Accuracy: 1.00000\n",
            "2.4874958992004395\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.4571099281311035\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 14/200, Loss: 2.47230, Accuracy: 1.00000\n",
            "2.4256763458251953\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.3966712951660156\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 15/200, Loss: 2.41117, Accuracy: 1.00000\n",
            "2.3582539558410645\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.3174517154693604\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 16/200, Loss: 2.33785, Accuracy: 1.00000\n",
            "2.2772984504699707\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.231569290161133\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 17/200, Loss: 2.25443, Accuracy: 1.00000\n",
            "2.186251640319824\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.133453845977783\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 18/200, Loss: 2.15985, Accuracy: 1.00000\n",
            "2.081258773803711\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "2.027198553085327\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 19/200, Loss: 2.05423, Accuracy: 1.00000\n",
            "1.9635857343673706\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "1.9101929664611816\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 20/200, Loss: 1.93689, Accuracy: 1.00000\n",
            "1.8405011892318726\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "1.7699687480926514\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 21/200, Loss: 1.80523, Accuracy: 1.00000\n",
            "1.6996170282363892\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "1.6284570693969727\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 22/200, Loss: 1.66404, Accuracy: 1.00000\n",
            "1.5483527183532715\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "1.4730058908462524\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 23/200, Loss: 1.51068, Accuracy: 1.00000\n",
            "1.3861249685287476\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "1.3064937591552734\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 24/200, Loss: 1.34631, Accuracy: 1.00000\n",
            "1.220075249671936\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "1.1259177923202515\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 25/200, Loss: 1.17300, Accuracy: 1.00000\n",
            "1.044886827468872\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.9527454376220703\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 26/200, Loss: 0.99882, Accuracy: 1.00000\n",
            "0.87842857837677\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.7724764943122864\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 27/200, Loss: 0.82545, Accuracy: 1.00000\n",
            "0.7060807943344116\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.6245115995407104\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 28/200, Loss: 0.66530, Accuracy: 1.00000\n",
            "0.5563309788703918\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.4800509512424469\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 29/200, Loss: 0.51819, Accuracy: 1.00000\n",
            "0.42162835597991943\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.36486950516700745\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 30/200, Loss: 0.39325, Accuracy: 1.00000\n",
            "0.31510791182518005\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.2654009461402893\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 31/200, Loss: 0.29025, Accuracy: 1.00000\n",
            "0.23025040328502655\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.1915287971496582\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 32/200, Loss: 0.21089, Accuracy: 1.00000\n",
            "0.16713659465312958\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.13628773391246796\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 33/200, Loss: 0.15171, Accuracy: 1.00000\n",
            "0.11831694096326828\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.10129286348819733\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 34/200, Loss: 0.10980, Accuracy: 1.00000\n",
            "0.08670102059841156\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.07232634723186493\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 35/200, Loss: 0.07951, Accuracy: 1.00000\n",
            "0.06305541098117828\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.054464466869831085\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 36/200, Loss: 0.05876, Accuracy: 1.00000\n",
            "0.047367651015520096\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.040825389325618744\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 37/200, Loss: 0.04410, Accuracy: 1.00000\n",
            "0.03606284037232399\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.03167306259274483\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 38/200, Loss: 0.03387, Accuracy: 1.00000\n",
            "0.028282158076763153\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.02485780417919159\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 39/200, Loss: 0.02657, Accuracy: 1.00000\n",
            "0.022827627137303352\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.019712239503860474\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 40/200, Loss: 0.02127, Accuracy: 1.00000\n",
            "0.018425825983285904\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.016571328043937683\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 41/200, Loss: 0.01750, Accuracy: 1.00000\n",
            "0.015547268092632294\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.013630248606204987\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 42/200, Loss: 0.01459, Accuracy: 1.00000\n",
            "0.012927246280014515\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.012089448980987072\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 43/200, Loss: 0.01251, Accuracy: 1.00000\n",
            "0.011142374016344547\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.010536888614296913\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 44/200, Loss: 0.01084, Accuracy: 1.00000\n",
            "0.009556521661579609\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.009617887437343597\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 45/200, Loss: 0.00959, Accuracy: 1.00000\n",
            "0.008763519115746021\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.008130707778036594\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 46/200, Loss: 0.00845, Accuracy: 1.00000\n",
            "0.0077403998002409935\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0075307018123567104\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 47/200, Loss: 0.00764, Accuracy: 1.00000\n",
            "0.007092443760484457\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.006734374910593033\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 48/200, Loss: 0.00691, Accuracy: 1.00000\n",
            "0.006493410561233759\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.006162900477647781\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 49/200, Loss: 0.00633, Accuracy: 1.00000\n",
            "0.005902854725718498\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0057966443710029125\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 50/200, Loss: 0.00585, Accuracy: 1.00000\n",
            "0.005489225033670664\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.005307050887495279\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 51/200, Loss: 0.00540, Accuracy: 1.00000\n",
            "0.005072617903351784\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0049600750207901\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 52/200, Loss: 0.00502, Accuracy: 1.00000\n",
            "0.004758944269269705\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.004559514578431845\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 53/200, Loss: 0.00466, Accuracy: 1.00000\n",
            "0.004421004094183445\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.004288482014089823\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 54/200, Loss: 0.00435, Accuracy: 1.00000\n",
            "0.004127987194806337\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.004021217115223408\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 55/200, Loss: 0.00407, Accuracy: 1.00000\n",
            "0.0038625048473477364\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.003769838949665427\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 56/200, Loss: 0.00382, Accuracy: 1.00000\n",
            "0.0035502975806593895\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0036493532825261354\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 57/200, Loss: 0.00360, Accuracy: 1.00000\n",
            "0.003387701464816928\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0033295361790806055\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 58/200, Loss: 0.00336, Accuracy: 1.00000\n",
            "0.0030746033880859613\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.003297108458355069\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 59/200, Loss: 0.00319, Accuracy: 1.00000\n",
            "0.0029905985575169325\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0029246557969599962\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 60/200, Loss: 0.00296, Accuracy: 1.00000\n",
            "0.0028432949911803007\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0026884593535214663\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 61/200, Loss: 0.00277, Accuracy: 1.00000\n",
            "0.0025576455518603325\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.002709760330617428\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 62/200, Loss: 0.00263, Accuracy: 1.00000\n",
            "0.002424179809167981\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.002508810255676508\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 63/200, Loss: 0.00247, Accuracy: 1.00000\n",
            "0.002455098321661353\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0020648743957281113\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 64/200, Loss: 0.00226, Accuracy: 1.00000\n",
            "0.0021880394779145718\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00213359366171062\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 65/200, Loss: 0.00216, Accuracy: 1.00000\n",
            "0.0020533499773591757\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0020091282203793526\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 66/200, Loss: 0.00203, Accuracy: 1.00000\n",
            "0.0019865024369210005\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0017951956251636147\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 67/200, Loss: 0.00189, Accuracy: 1.00000\n",
            "0.0017770244739949703\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0018365374999120831\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 68/200, Loss: 0.00181, Accuracy: 1.00000\n",
            "0.001669171848334372\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0017299182945862412\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 69/200, Loss: 0.00170, Accuracy: 1.00000\n",
            "0.0016327743651345372\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0015248158015310764\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 70/200, Loss: 0.00158, Accuracy: 1.00000\n",
            "0.0015566329238936305\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0014020561939105392\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 71/200, Loss: 0.00148, Accuracy: 1.00000\n",
            "0.0014129166956990957\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0014070108300074935\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 72/200, Loss: 0.00141, Accuracy: 1.00000\n",
            "0.0013398316223174334\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0013113018358126283\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 73/200, Loss: 0.00133, Accuracy: 1.00000\n",
            "0.0012897400883957744\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0011927761370316148\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 74/200, Loss: 0.00124, Accuracy: 1.00000\n",
            "0.0011868944857269526\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0011744981165975332\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 75/200, Loss: 0.00118, Accuracy: 1.00000\n",
            "0.0011304608779028058\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.001092407270334661\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 76/200, Loss: 0.00111, Accuracy: 1.00000\n",
            "0.0010530210565775633\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0010569216683506966\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 77/200, Loss: 0.00105, Accuracy: 1.00000\n",
            "0.000986505881883204\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0010146277491003275\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 78/200, Loss: 0.00100, Accuracy: 1.00000\n",
            "0.000951961032114923\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0009301744285039604\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 79/200, Loss: 0.00094, Accuracy: 1.00000\n",
            "0.0009159639594145119\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0008575438987463713\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 80/200, Loss: 0.00089, Accuracy: 1.00000\n",
            "0.0008704568026587367\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0008094995282590389\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 81/200, Loss: 0.00084, Accuracy: 1.00000\n",
            "0.0008021225803531706\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0008074748911894858\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 82/200, Loss: 0.00080, Accuracy: 1.00000\n",
            "0.0007539892685599625\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0007800297462381423\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 83/200, Loss: 0.00077, Accuracy: 1.00000\n",
            "0.0007354856934398413\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0007108391146175563\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 84/200, Loss: 0.00072, Accuracy: 1.00000\n",
            "0.0006682636449113488\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0007284510065801442\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 85/200, Loss: 0.00070, Accuracy: 1.00000\n",
            "0.0006616014870814979\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0006524951895698905\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 86/200, Loss: 0.00066, Accuracy: 1.00000\n",
            "0.0006203646771609783\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0006389818736352026\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 87/200, Loss: 0.00063, Accuracy: 1.00000\n",
            "0.000615449040196836\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0005710269324481487\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 88/200, Loss: 0.00059, Accuracy: 1.00000\n",
            "0.0005915045621804893\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.000539038039278239\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 89/200, Loss: 0.00057, Accuracy: 1.00000\n",
            "0.0005688405362889171\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0005097503890283406\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 90/200, Loss: 0.00054, Accuracy: 1.00000\n",
            "0.0005205742199905217\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0005269297398626804\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 91/200, Loss: 0.00052, Accuracy: 1.00000\n",
            "0.000500267546158284\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.000501845614053309\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 92/200, Loss: 0.00050, Accuracy: 1.00000\n",
            "0.00047026691026985645\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0004962916136719286\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 93/200, Loss: 0.00048, Accuracy: 1.00000\n",
            "0.0004753671819344163\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00043602086952887475\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 94/200, Loss: 0.00046, Accuracy: 1.00000\n",
            "0.00045347376726567745\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0004233575891703367\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 95/200, Loss: 0.00044, Accuracy: 1.00000\n",
            "0.00042100093560293317\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00043115150765515864\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 96/200, Loss: 0.00043, Accuracy: 1.00000\n",
            "0.0004269358469173312\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00037794510717503726\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 97/200, Loss: 0.00040, Accuracy: 1.00000\n",
            "0.0004011420242022723\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0003797943936660886\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 98/200, Loss: 0.00039, Accuracy: 1.00000\n",
            "0.00038325207424350083\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00037076440639793873\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 99/200, Loss: 0.00038, Accuracy: 1.00000\n",
            "0.0003743564593605697\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0003491257375571877\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 100/200, Loss: 0.00036, Accuracy: 1.00000\n",
            "0.0003466094785835594\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0003605847305152565\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 101/200, Loss: 0.00035, Accuracy: 1.00000\n",
            "0.00035163701977580786\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00031960339401848614\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 102/200, Loss: 0.00034, Accuracy: 1.00000\n",
            "0.0003332031483296305\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0003192147414665669\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 103/200, Loss: 0.00033, Accuracy: 1.00000\n",
            "0.00031694411882199347\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0003167494433000684\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 104/200, Loss: 0.00032, Accuracy: 1.00000\n",
            "0.0003047622158192098\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0003091232792939991\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 105/200, Loss: 0.00031, Accuracy: 1.00000\n",
            "0.00029445780091919005\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00029962052940391004\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 106/200, Loss: 0.00030, Accuracy: 1.00000\n",
            "0.00029841624200344086\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0002677012817002833\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 107/200, Loss: 0.00028, Accuracy: 1.00000\n",
            "0.0002778888738248497\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00027781788958236575\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 108/200, Loss: 0.00028, Accuracy: 1.00000\n",
            "0.0002731219574343413\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00026287062792107463\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 109/200, Loss: 0.00027, Accuracy: 1.00000\n",
            "0.0002610368246678263\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00026108286692760885\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 110/200, Loss: 0.00026, Accuracy: 1.00000\n",
            "0.0002592192031443119\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00024323146499227732\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 111/200, Loss: 0.00025, Accuracy: 1.00000\n",
            "0.0002522250288166106\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00023492646869271994\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 112/200, Loss: 0.00024, Accuracy: 1.00000\n",
            "0.0002319271443411708\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00024975513224489987\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 113/200, Loss: 0.00024, Accuracy: 1.00000\n",
            "0.0002289662224939093\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0002364697866141796\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 114/200, Loss: 0.00023, Accuracy: 1.00000\n",
            "0.00022790851653553545\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00022087579418439418\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 115/200, Loss: 0.00022, Accuracy: 1.00000\n",
            "0.0002194577391492203\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0002182789467042312\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 116/200, Loss: 0.00022, Accuracy: 1.00000\n",
            "0.0002126196923200041\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00021372485207393765\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 117/200, Loss: 0.00021, Accuracy: 1.00000\n",
            "0.0002070815535262227\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00020765248336829245\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 118/200, Loss: 0.00021, Accuracy: 1.00000\n",
            "0.00020375930762384087\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00019846907525788993\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 119/200, Loss: 0.00020, Accuracy: 1.00000\n",
            "0.00019166196580044925\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00020444100664462894\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 120/200, Loss: 0.00020, Accuracy: 1.00000\n",
            "0.0001907010591821745\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00019253497885074466\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 121/200, Loss: 0.00019, Accuracy: 1.00000\n",
            "0.00018267484847456217\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00019294863159302622\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 122/200, Loss: 0.00019, Accuracy: 1.00000\n",
            "0.00018292403547093272\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0001800080353859812\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 123/200, Loss: 0.00018, Accuracy: 1.00000\n",
            "0.0001796539727365598\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0001733459357637912\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 124/200, Loss: 0.00018, Accuracy: 1.00000\n",
            "0.00017131070489995182\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00017581770953256637\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 125/200, Loss: 0.00017, Accuracy: 1.00000\n",
            "0.00017475991626270115\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00015878603153396398\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 126/200, Loss: 0.00017, Accuracy: 1.00000\n",
            "0.00016129146388266236\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00017053575720638037\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 127/200, Loss: 0.00017, Accuracy: 1.00000\n",
            "0.00016256152593996376\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00015810875629540533\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 128/200, Loss: 0.00016, Accuracy: 1.00000\n",
            "0.0001550414744997397\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00016066811804194003\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 129/200, Loss: 0.00016, Accuracy: 1.00000\n",
            "0.0001559465454192832\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00014955212827771902\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 130/200, Loss: 0.00015, Accuracy: 1.00000\n",
            "0.00015149189857766032\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00014768255641683936\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 131/200, Loss: 0.00015, Accuracy: 1.00000\n",
            "0.00014988271868787706\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00014137185644358397\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 132/200, Loss: 0.00015, Accuracy: 1.00000\n",
            "0.00013716652756556869\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0001539622462587431\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 133/200, Loss: 0.00015, Accuracy: 1.00000\n",
            "0.00014431067393161356\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00013369943189900368\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 134/200, Loss: 0.00014, Accuracy: 1.00000\n",
            "0.00013620543177239597\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00013908845721744\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 135/200, Loss: 0.00014, Accuracy: 1.00000\n",
            "0.00014549511251971126\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00011586455366341397\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 136/200, Loss: 0.00013, Accuracy: 1.00000\n",
            "0.00013415320427156985\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00012714395415969193\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 137/200, Loss: 0.00013, Accuracy: 1.00000\n",
            "0.0001328011421719566\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00012222558143548667\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 138/200, Loss: 0.00013, Accuracy: 1.00000\n",
            "0.00012691969459410757\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00012485409388318658\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 139/200, Loss: 0.00013, Accuracy: 1.00000\n",
            "0.00011650880333036184\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0001354875712422654\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 140/200, Loss: 0.00013, Accuracy: 1.00000\n",
            "0.00012385040463414043\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00011659843585221097\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 141/200, Loss: 0.00012, Accuracy: 1.00000\n",
            "0.0001182781852548942\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00011944007565034553\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 142/200, Loss: 0.00012, Accuracy: 1.00000\n",
            "0.00011931367771467194\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0001113850375986658\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 143/200, Loss: 0.00012, Accuracy: 1.00000\n",
            "0.00011523481225594878\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00011220087617402896\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 144/200, Loss: 0.00011, Accuracy: 1.00000\n",
            "0.00011871768947457895\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00010049438424175605\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 145/200, Loss: 0.00011, Accuracy: 1.00000\n",
            "0.00011027716391254216\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00010886944073718041\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 146/200, Loss: 0.00011, Accuracy: 1.00000\n",
            "0.00011019143130397424\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00010361864406149834\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 147/200, Loss: 0.00011, Accuracy: 1.00000\n",
            "0.00010095006291521713\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.0001136624050559476\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 148/200, Loss: 0.00011, Accuracy: 1.00000\n",
            "0.00010140822996618226\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00010768377978820354\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 149/200, Loss: 0.00010, Accuracy: 1.00000\n",
            "0.0001023840595735237\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "0.00010088970884680748\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 150/200, Loss: 0.00010, Accuracy: 1.00000\n",
            "0.00010108413698617369\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "9.811043128138408e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 151/200, Loss: 0.00010, Accuracy: 1.00000\n",
            "9.933714318322018e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "9.632250294089317e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 152/200, Loss: 0.00010, Accuracy: 1.00000\n",
            "9.667752601671964e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "9.60277029662393e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 153/200, Loss: 0.00010, Accuracy: 1.00000\n",
            "9.41967373364605e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "9.56512667471543e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 154/200, Loss: 0.00009, Accuracy: 1.00000\n",
            "8.971563511295244e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "9.869399218587205e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 155/200, Loss: 0.00009, Accuracy: 1.00000\n",
            "8.992431685328484e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "9.408274490851909e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 156/200, Loss: 0.00009, Accuracy: 1.00000\n",
            "9.474436228629202e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "8.174894173862413e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 157/200, Loss: 0.00009, Accuracy: 1.00000\n",
            "9.104549826588482e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "8.395723853027448e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 158/200, Loss: 0.00009, Accuracy: 1.00000\n",
            "8.871734462445602e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "8.378168422495946e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 159/200, Loss: 0.00009, Accuracy: 1.00000\n",
            "8.754030568525195e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "8.187443745555356e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 160/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "8.583057933719829e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "8.094587246887386e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 161/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "8.254515705630183e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "8.271505794255063e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 162/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "8.177407289622352e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "8.056321530602872e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 163/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "7.924478268250823e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "8.12345533631742e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 164/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "8.194538531824946e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "7.334858673857525e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 165/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "8.042193076107651e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "7.257682591443881e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 166/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "7.64025971875526e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "7.598980300826952e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 167/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "7.337048009503633e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "7.795971032464877e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 168/200, Loss: 0.00008, Accuracy: 1.00000\n",
            "7.565389387309551e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "7.092064333846793e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 169/200, Loss: 0.00007, Accuracy: 1.00000\n",
            "7.173890480771661e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "7.455939339706674e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 170/200, Loss: 0.00007, Accuracy: 1.00000\n",
            "7.121740782167763e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "7.252043724292889e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 171/200, Loss: 0.00007, Accuracy: 1.00000\n",
            "6.95150883984752e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "7.244512380566448e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 172/200, Loss: 0.00007, Accuracy: 1.00000\n",
            "6.976095028221607e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.923924956936389e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 173/200, Loss: 0.00007, Accuracy: 1.00000\n",
            "6.967528315726668e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.669838330708444e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 174/200, Loss: 0.00007, Accuracy: 1.00000\n",
            "6.64866529405117e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.922669854247943e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 175/200, Loss: 0.00007, Accuracy: 1.00000\n",
            "6.64717736071907e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.666698027402163e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 176/200, Loss: 0.00007, Accuracy: 1.00000\n",
            "6.767492595827207e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.204956298461184e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 177/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "6.511210813187063e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.373718497343361e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 178/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "6.283238326432183e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.513624975923449e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 179/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "6.111889524618164e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.557535380125046e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 180/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "6.286963616730645e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.029917858541012e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 181/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "6.0776150348829105e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.149121327325702e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 182/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "6.127906090114266e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.841072561452165e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 183/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "5.779612183687277e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "6.20307182543911e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 184/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "5.937926471233368e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.714972212444991e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 185/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "5.693561979569495e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.914479697821662e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 186/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "5.8429348428035155e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.450849494081922e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 187/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "5.639920709654689e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.595770926447585e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 188/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "5.5553628044435754e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.534912634175271e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 189/200, Loss: 0.00006, Accuracy: 1.00000\n",
            "5.411947495304048e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.579456046689302e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 190/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "5.404868716141209e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.4025378631195053e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 191/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "5.4931530030444264e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.066260928288102e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 192/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "5.522953870240599e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "4.8316189349861816e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 193/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "5.247298759059049e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.108293771627359e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 194/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "5.0815313443308696e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.216833596932702e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 195/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "4.890062700724229e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.359874194255099e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 196/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "4.9623282393440604e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "5.068770406069234e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 197/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "4.9884056352311745e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "4.86361350340303e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 198/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "5.0103841203963384e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "4.6590848796768114e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 199/200, Loss: 0.00005, Accuracy: 1.00000\n",
            "4.846477895625867e-05\n",
            "torch.Size([32, 18])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "32.0\n",
            "32\n",
            "4.7732719394844025e-05\n",
            "torch.Size([19, 18])\n",
            "torch.Size([19])\n",
            "torch.Size([19])\n",
            "51.0\n",
            "51\n",
            "Epoch 200/200, Loss: 0.00005, Accuracy: 1.00000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "#  (Feedforward Neural Network) ->  (MLP: Multi-Layer Perceptron)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import glob\n",
        "import string\n",
        "\n",
        "unknown_char,padding = '?','_'\n",
        "all_letters = string.ascii_lowercase + unknown_char + padding\n",
        "category_names,all_categories = {},[]\n",
        "max_word_length,batch_size = 10,32\n",
        "len_all_categories=0\n",
        "test_size,val_size = 0.2, 0.1\n",
        "\n",
        "def activate_config(unknown_char='?', padding='_', max_word_length=10, batch_size=32, test_size=0.2, val_size=0.1):\n",
        "    unknown_char,padding = unknown_char,padding\n",
        "    all_letters = string.ascii_lowercase + unknown_char + padding\n",
        "    max_word_length,batch_size = max_word_length,batch_size\n",
        "    test_size=test_size\n",
        "    val_size=val_size\n",
        "\n",
        "def category_to_tensor(idx, N):\n",
        "    return torch.tensor([(i==idx)/1 for i in range(N)])\n",
        "\n",
        "def input_padding_and_unknown_char_handling(word):\n",
        "    word = ''.join(char if char in string.ascii_lowercase else unknown_char for char in word.lower())\n",
        "    return word + '_'*(10 - len(word)) if len(word)!=10 else word\n",
        "\n",
        "def word_to_tensor(word):\n",
        "    word = input_padding_and_unknown_char_handling(word)\n",
        "    res = torch.zeros(len(word), len(all_letters))\n",
        "    for idx, letter in enumerate(word):\n",
        "        res[idx][all_letters.find(letter)] = 1\n",
        "    # print(word, res, res.shape)\n",
        "    return res #.squeeze(dim = 1) # shape(10,28)    \n",
        "\n",
        "def preprocessing_data(batch_size = 32, test_size=0.2, val_size=0.1):\n",
        "    files = glob.glob('./data/names/*.txt')\n",
        "    # print(f'{len(files)}fiels',*files,sep='\\n')\n",
        "    \n",
        "    for file in files:\n",
        "        with open(file) as f:\n",
        "            words = f.read().strip().split('\\n')\n",
        "        category = file.split('\\\\')[-1].split('.')[0]\n",
        "        all_categories.append(category)\n",
        "\n",
        "        words = [word for word in words if len(word) <= max_word_length]\n",
        "        category_names[category] = words\n",
        "        # print(f'{category}: {len(words)} |', *words[0:10])\n",
        "    # print(all_categories)\n",
        "    # print(category_names)\n",
        "\n",
        "    \n",
        "    for category, words in category_names.items():\n",
        "        x = [word_to_tensor(word) for word in words]\n",
        "        y = [torch.tensor(all_categories.index(category)) for word in words]\n",
        "    \n",
        "    x = torch.stack(x)\n",
        "    y = torch.stack(y)\n",
        "\n",
        "    x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=(test_size + val_size))\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=(test_size / (test_size + val_size)))\n",
        "    \n",
        "    train_dataset = TensorDataset(x_train, y_train)\n",
        "    val_dataset = TensorDataset(x_val, y_val)\n",
        "    test_dataset = TensorDataset(x_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def plot_loss_history(loss_history, val_loss_history=None): # , \n",
        "    plt.figure(figsize=(10, 6)) \n",
        "    plt.plot(range(1, len(loss_history) + 1), loss_history, label='Training Loss', color='blue', marker='o')\n",
        "    if val_loss_history is not None: plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, label='Validation Loss', color='orange', marker='x')\n",
        "    plt.title('Loss History')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xticks(range(1, len(loss_history) + 1)) # x  \n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.input_hidden = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden_hidden = nn.Linear(hidden_size, hidden_size)\n",
        "        self.hidden_output = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim = 1) #   \n",
        "        self.optimizer = optim.Adam #   ()    #  ()    \n",
        "        self.loss = torch.nn.NLLLoss() #        :       \n",
        "\n",
        "    def forward(self, input):\n",
        "        hidden = self.relu(self.input_hidden(input))\n",
        "        hidden = self.relu(self.hidden_hidden(hidden))\n",
        "        output = self.hidden_output(hidden)\n",
        "        output = self.softmax(output)\n",
        "        return output\n",
        "    \n",
        "    def train_model(self, train_data, learning_rate = 0.001, epochs = 20):\n",
        "        optimizer = self.optimizer(self.parameters(), lr = learning_rate)\n",
        "        loss_history = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            correct_predictions = 0\n",
        "            total_predictions = 0\n",
        "            \n",
        "            for input, label in train_data:\n",
        "                input = input.reshape(input.size(0), input.size(1)*input.size(2))\n",
        "                label = label.long()  # label LongTensor \n",
        "                # hidden = self.initHidden() #   # MLP        #RNN  \n",
        "                optimizer.zero_grad()\n",
        "                output = self(input)#   \n",
        "                # print(output)\n",
        "                \n",
        "                loss = self.loss(output, label)\n",
        "                loss.backward() #  \n",
        "                optimizer.step() #  \n",
        "                \n",
        "                running_loss += loss.item() # \n",
        "                \n",
        "                print(torch.mean(loss).item())\n",
        "                print(output.shape)\n",
        "                # predicted = output.argmax(1)  #    \n",
        "                predicted = torch.argmax(output, 1)  #    \n",
        "                \n",
        "                print(predicted.shape)\n",
        "                print(label.shape)\n",
        "                correct_predictions += (predicted == label).float().sum().item()  #   \n",
        "                total_predictions += label.size(0)  #   \n",
        "                print(correct_predictions)\n",
        "                print(total_predictions)\n",
        "                \n",
        "                if len(loss_history)%1000 == 0:\n",
        "                    print(torch.mean(loss).item())\n",
        "            \n",
        "            \n",
        "            epoch_loss = running_loss / len(train_data)\n",
        "            accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0 #  \n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.5f}, Accuracy: {accuracy:.5f}') #  \n",
        "            loss_history.append(epoch_loss)  #  \n",
        "        plot_loss_history(loss_history)\n",
        "        return loss_history\n",
        "\n",
        "def predict_nationality(model, word):\n",
        "    word_tensor = word_to_tensor(word).unsqueeze(0)\n",
        "    print(word_tensor.shape)\n",
        "    \n",
        "    output = model(word_tensor)\n",
        "    _, predicted_index = torch.max(output, 1)\n",
        "    return predicted_index\n",
        "\n",
        "activate_config(unknown_char='?', padding='_',\n",
        "                max_word_length=10, batch_size=32,\n",
        "                test_size=0.2, val_size=0.1)\n",
        "train_loader, val_loader, test_loader = preprocessing_data(batch_size,test_size,val_size)\n",
        "\n",
        "model = MLP(input_size=len(all_letters)*10, hidden_size=32, output_size=len(all_categories))\n",
        "# predict_nationality(model, 'ang')\n",
        "\n",
        "model.train_model(train_loader, learning_rate = 0.001, epochs = 200)\n",
        "print(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "          a z  .\n",
        "\n",
        "   names     ,       .  ,       ,  /  .\n",
        "\n",
        "1. Feedforward Network(MLP)   .\n",
        "  -  Feedforward Network   , input size          \n",
        "2. RNN   .\n",
        "  - torch.DataLoader   batching  ,    1            . torch.DataLoader       .\n",
        "  -    ,         .\n",
        "  -     OOV         \n",
        "\n",
        "   train-valid-test  , valid loss        .\n",
        "\n",
        "      .\n",
        "\n",
        "- hyperparameter   \n",
        "-      \n",
        "-     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1})\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "d = defaultdict(int)\n",
        "\n",
        "for i in range(10):\n",
        "    d[i] += 1\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "word2tensor() missing 2 required positional arguments: 'max_length' and 'alphabets'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 93\u001b[0m\n\u001b[0;32m     88\u001b[0m alphabets \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabcdefghijklmnopqrstuvwxzy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m17\u001b[39m\n\u001b[1;32m---> 93\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n",
            "Cell \u001b[1;32mIn[9], line 75\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m             tmp\u001b[38;5;241m.\u001b[39mappend(oov)\n\u001b[1;32m---> 75\u001b[0m     data[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mword2tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([e[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[0;32m     78\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mtensor(e[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m data])\n",
            "\u001b[1;31mTypeError\u001b[0m: word2tensor() missing 2 required positional arguments: 'max_length' and 'alphabets'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "def generate_dataset(batch_size = 32):\n",
        "    files = glob.glob('./data/names/*.txt')\n",
        "\n",
        "    assert len(files) == 18\n",
        "\n",
        "    character_dict = defaultdict(int)\n",
        "    name_length_dict = defaultdict(int)\n",
        "\n",
        "    data = []\n",
        "    languages = []\n",
        "\n",
        "    for file in files:\n",
        "        with open(file) as f:\n",
        "            names = f.read().strip().split('\\n')\n",
        "        lang = file.split('/')[1].split('.')[0]\n",
        "\n",
        "        if lang not in languages:\n",
        "            languages.append(lang)\n",
        "\n",
        "        for name in names:\n",
        "            for char in name:\n",
        "                character_dict[char.lower()] += 1\n",
        "            name_length_dict[len(name)] += 1\n",
        "            data.append([name, lang])\n",
        "\n",
        "    lst = []\n",
        "    for k, v in character_dict.items():\n",
        "        lst.append((k, v))\n",
        "\n",
        "    name_length_lst = []\n",
        "    for k, v in name_length_dict.items():\n",
        "        name_length_lst.append((k, v))\n",
        "\n",
        "    lst = sorted(lst, key = lambda x:x[1], reverse = True)\n",
        "    name_length_lst = sorted(name_length_lst, key = lambda x:x[1], reverse = True)\n",
        "\n",
        "    total_count = sum([e[1] for e in lst])\n",
        "    total_count_name = sum([e[1] for e in name_length_lst])\n",
        "\n",
        "    s = 0\n",
        "    alphabets = []\n",
        "\n",
        "    oov = '[OOV]'\n",
        "    pad = '[PAD]'\n",
        "\n",
        "    for k, v in lst:\n",
        "        s += v\n",
        "        if s < 0.999*total_count:\n",
        "            alphabets.append(k)\n",
        "    s = 0\n",
        "    max_length_candidate = []\n",
        "    for k, v in name_length_lst:\n",
        "        s += v\n",
        "        if s < 0.999*total_count_name:\n",
        "            max_length_candidate.append(k)\n",
        "\n",
        "    alphabets.append(oov)\n",
        "\n",
        "    for elem in data:\n",
        "        tmp = []\n",
        "        for char in data[0]:\n",
        "            if char in alphabets:\n",
        "                tmp.append(char)\n",
        "            else:\n",
        "                tmp.append(oov)\n",
        "        data[0] = word2tensor(tmp)\n",
        "\n",
        "    x = torch.stack([e[0] for e in data])\n",
        "    y = torch.stack([torch.tensor(e[1]) for e in data])\n",
        "\n",
        "    dataset = TensorDataset(x, y)\n",
        "    dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "# now the data is list of[list of character, lang_name]\n",
        "\n",
        "alphabets = 'abcdefghijklmnopqrstuvwxzy'\n",
        "max_length = 17\n",
        "\n",
        "\n",
        "\n",
        "dataset = generate_dataset()\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'o', 'e', 'i', 'n', 'r', 's', 'h', 'k', 'l', 'v', 't', 'u', 'm', 'd', 'b', 'y', 'g', 'c', 'z', 'f', 'p', 'j', 'w', ' ', 'q', \"'\", 'x', '-', '', '[PAD]', '[OOV]'] 12\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'split_train_valid_test' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 152\u001b[0m\n\u001b[0;32m    148\u001b[0m     test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size \u001b[38;5;241m=\u001b[39m batch_size, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_dataloader, valid_dataloader, test_dataloader, alphabets, max_length, languages\n\u001b[1;32m--> 152\u001b[0m train_dataset, valid_dataset, test_dataset, alphabets, max_length, languages  \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[6], line 133\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[1;34m(batch_size, pad, oov)\u001b[0m\n\u001b[0;32m    130\u001b[0m x \u001b[38;5;241m=\u001b[39m [e[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    131\u001b[0m y \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(e[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m--> 133\u001b[0m train_x, train_y, valid_x, valid_y, test_x, test_y \u001b[38;5;241m=\u001b[39m \u001b[43msplit_train_valid_test\u001b[49m(x, y)\n\u001b[0;32m    135\u001b[0m train_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(train_x)\n\u001b[0;32m    136\u001b[0m train_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(train_y)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'split_train_valid_test' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "OOV = '[OOV]'\n",
        "PAD = '[PAD]'\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 32\n",
        "\n",
        "def letter2tensor(letter, alphabets, oov = OOV):\n",
        "    res = [0 for _ in range(len(alphabets))]\n",
        "\n",
        "    if letter in alphabets:\n",
        "        idx = alphabets.index(letter)\n",
        "    else:\n",
        "        idx = alphabets.index(oov)\n",
        "\n",
        "    res[idx] = 1\n",
        "\n",
        "    return torch.tensor(res)\n",
        "\n",
        "def word2tensor(word, max_length, alphabets, pad = PAD, oov = OOV):\n",
        "    # return torch.tensor with size (max_length, len(alphabets))\n",
        "    res = torch.zeros(max_length, len(alphabets))\n",
        "\n",
        "    for idx, char in enumerate(word):\n",
        "        if idx < max_length:\n",
        "            res[idx] = letter2tensor(char, alphabets, oov = oov)\n",
        "\n",
        "    for i in range(max_length - len(word)):\n",
        "        res[len(word) + i] = letter2tensor(pad, alphabets, oov = oov)\n",
        "\n",
        "    return res\n",
        "\n",
        "def determine_alphabets(data, pad = PAD, oov = OOV, threshold = 0.999):\n",
        "    # data = list of [name, language_name]\n",
        "    lst = []\n",
        "    character_dict = defaultdict(int)\n",
        "\n",
        "    for name, lang in data:\n",
        "        for char in name:\n",
        "            character_dict[char.lower()] += 1\n",
        "\n",
        "    for k, v in character_dict.items():\n",
        "        lst.append((k, v))\n",
        "\n",
        "    lst = sorted(lst, key = lambda x:x[1], reverse = True)\n",
        "    total_count = sum([e[1] for e in lst])\n",
        "    s = 0\n",
        "\n",
        "    alphabets = []\n",
        "\n",
        "    for k, v in lst:\n",
        "        s += v\n",
        "        if s < threshold * total_count:\n",
        "            alphabets.append(k)\n",
        "\n",
        "    alphabets.append(pad)\n",
        "    alphabets.append(oov)\n",
        "\n",
        "    return alphabets\n",
        "\n",
        "def determine_max_length(data, threshold = 0.99):\n",
        "    lst = []\n",
        "    name_length_dict = defaultdict(int)\n",
        "\n",
        "    for name, lang in data:\n",
        "         name_length_dict[len(name)] += 1\n",
        "\n",
        "    for k, v in name_length_dict.items():\n",
        "        lst.append((k, v))\n",
        "\n",
        "    lst = sorted(lst, key = lambda x:x[1], reverse = True)\n",
        "    total_count = sum([e[1] for e in lst])\n",
        "    s = 0\n",
        "\n",
        "    for k, v in lst:\n",
        "        s += v\n",
        "        if s > threshold * total_count:\n",
        "            return k - 1\n",
        "    # if not, return the maximum value in lst\n",
        "    return max(lst, key = lambda x:x[0])[0]\n",
        "\n",
        "def load_file(): \n",
        "    files = glob.glob('./data/names/*.txt')\n",
        "    \n",
        "    assert len(files) == 18\n",
        "\n",
        "    data = []\n",
        "    languages = []\n",
        "\n",
        "    for file in files:\n",
        "        with open(file) as f:\n",
        "            names = f.read().strip().split('\\n')\n",
        "        lang = file.split('/')[1].split('.')[0]\n",
        "\n",
        "        if lang not in languages:\n",
        "            languages.append(lang)\n",
        "\n",
        "        for name in names:\n",
        "            data.append([name, lang])\n",
        "\n",
        "    return data, languages\n",
        "\n",
        "def generate_dataset(batch_size = 32, pad = PAD, oov = OOV):\n",
        "    data, languages = load_file()\n",
        "\n",
        "    alphabets = determine_alphabets(data, pad = pad, oov = oov)\n",
        "    max_length = determine_max_length(data)\n",
        "    print(alphabets, max_length)\n",
        "\n",
        "    for idx, elem in enumerate(data):\n",
        "        tmp = []\n",
        "        for char in elem[0]:\n",
        "            if char.lower() in alphabets:\n",
        "                tmp.append(char.lower())\n",
        "            else:\n",
        "                tmp.append(oov)\n",
        "\n",
        "        data[idx][0] = word2tensor(tmp, max_length, alphabets, pad = pad, oov = oov)\n",
        "        data[idx][1] = languages.index(data[idx][1])\n",
        "\n",
        "    x = [e[0] for e in data]\n",
        "    y = [torch.tensor(e[1]) for e in data]\n",
        "\n",
        "    train_x, train_y, valid_x, valid_y, test_x, test_y = split_train_valid_test(x, y)\n",
        "\n",
        "    train_x = torch.stack(train_x)\n",
        "    train_y = torch.stack(train_y)\n",
        "    valid_x = torch.stack(valid_x)\n",
        "    valid_y = torch.stack(valid_y)\n",
        "    test_x = torch.stack(test_x)\n",
        "    test_y = torch.stack(test_y)\n",
        "\n",
        "    train_dataset = TensorDataset(train_x, train_y)\n",
        "    valid_dataset = TensorDataset(valid_x, valid_y)\n",
        "    test_dataset = TensorDataset(test_x, test_y)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "    return train_dataloader, valid_dataloader, test_dataloader, alphabets, max_length, languages\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset, alphabets, max_length, languages  = generate_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x, y in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = torch.randn(3,4,2)\n",
        "print(t)\n",
        "print(t.reshape(3, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'size'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m languages[idx]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mbatch_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(tensor2word(batch_x[i], alphabets), idx2lang(batch_y[i], languages))\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ],
      "source": [
        "def tensor2word(t, alphabets):\n",
        "    # t.shpae: max_length, len(alphabets)\n",
        "    res = []\n",
        "    for char_tensor in t:\n",
        "        char = alphabets[int(torch.argmax(char_tensor).item())]\n",
        "        res.append(char)\n",
        "\n",
        "    return res\n",
        "\n",
        "def idx2lang(idx, languages):\n",
        "    return languages[idx]\n",
        "\n",
        "for batch_x, batch_y in dataset:\n",
        "    for i in range(batch_x.size(0)):\n",
        "        print(tensor2word(batch_x[i], alphabets), idx2lang(batch_y[i], languages))\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def pick_train_valid_test(train, valid, test):\n",
        "    assert [train, valid, test] != [0, 0, 0]\n",
        "    options = [train, valid, test]\n",
        "\n",
        "    pick = random.choice([0, 1, 2])\n",
        "\n",
        "    while options[pick] == 0:\n",
        "        pick = random.choice([0, 1, 2])\n",
        "    assert options[pick] != 0\n",
        "    return pick\n",
        "\n",
        "print(pick_train_valid_test(0,3,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "t = torch.tensor([1.0, 2.0])\n",
        "print(t.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'size'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 153\u001b[0m\n\u001b[0;32m    150\u001b[0m                 total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    151\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(loss_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loss_list), correct \u001b[38;5;241m/\u001b[39m total\n\u001b[1;32m--> 153\u001b[0m train_data, valid_data, test_data \u001b[38;5;241m=\u001b[39m \u001b[43mmodify_dataset_for_ffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m model \u001b[38;5;241m=\u001b[39m FeedForwardNetwork(\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m    156\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(train_data)\n",
            "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36mmodify_dataset_for_ffn\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mbatch_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m     10\u001b[0m         x\u001b[38;5;241m.\u001b[39mappend(batch_x[i]\u001b[38;5;241m.\u001b[39mreshape((batch_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))))\n\u001b[0;32m     11\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(batch_y[i])\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import pickle\n",
        "\n",
        "def modify_dataset_for_ffn(dataset):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for batch_x, batch_y in dataset:\n",
        "        for i in range(batch_x.size(0)):\n",
        "            x.append(batch_x[i].reshape((batch_x.size(1) * batch_x.size(2))))\n",
        "            y.append(batch_y[i])\n",
        "\n",
        "    train_x, train_y, valid_x, valid_y, test_x, test_y = split_train_valid_test(x, y)\n",
        "\n",
        "    train_x = torch.stack(train_x)\n",
        "    train_y = torch.stack(train_y)\n",
        "    valid_x = torch.stack(valid_x)\n",
        "    valid_y = torch.stack(valid_y)\n",
        "    test_x = torch.stack(test_x)\n",
        "    test_y = torch.stack(test_y)\n",
        "\n",
        "    train_dataset = TensorDataset(train_x, train_y)\n",
        "    valid_dataset = TensorDataset(valid_x, valid_y)\n",
        "    test_dataset = TensorDataset(test_x, test_y)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "    return train_dataloader, valid_dataloader, test_dataloader\n",
        "\n",
        "def pick_train_valid_test(train, valid, test):\n",
        "    assert [train, valid, test] != [0, 0, 0]\n",
        "    options = [train, valid, test]\n",
        "\n",
        "    pick = random.choice([0, 1, 2])\n",
        "\n",
        "    while options[pick] == 0:\n",
        "        pick = random.choice([0, 1, 2])\n",
        "    assert options[pick] != 0\n",
        "    return pick\n",
        "\n",
        "def split_train_valid_test(x, y, train_valid_test_ratio = (0.7, 0.15, 0.15)):\n",
        "    # TensorDataset -> TensorDataset, TensorDataset, TensorDataset\n",
        "    # x, y: list of data\n",
        "    train_ratio, valid_ratio, test_ratio = train_valid_test_ratio\n",
        "    y_label_dict = defaultdict(int)\n",
        "    for y_data in y:\n",
        "        y_label_dict[y_data.item()] += 1\n",
        "\n",
        "    no_per_labels = {} # y_label  train, valid, test\n",
        "\n",
        "    for y_label, freq in y_label_dict.items():\n",
        "        train_size, valid_size, test_size = int(freq * train_ratio), int(freq * valid_ratio), freq - int(freq * train_ratio) - int(freq * valid_ratio)\n",
        "        no_per_labels[y_label] = [train_size, valid_size, test_size]\n",
        "\n",
        "    train_x, train_y = [], []\n",
        "    valid_x, valid_y = [], []\n",
        "    test_x, test_y = [], []\n",
        "\n",
        "    for x_data, y_data in zip(x, y):\n",
        "        idx = pick_train_valid_test(*no_per_labels[y_data.item()])\n",
        "        assert no_per_labels[y_data.item()][idx] > 0\n",
        "        no_per_labels[y_data.item()][idx] -= 1\n",
        "\n",
        "        if idx == 0:\n",
        "            train_x.append(x_data)\n",
        "            train_y.append(y_data)\n",
        "        elif idx == 1:\n",
        "            valid_x.append(x_data)\n",
        "            valid_y.append(y_data)\n",
        "        elif idx == 2:\n",
        "            test_x.append(x_data)\n",
        "            test_y.append(y_data)\n",
        "\n",
        "    return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
        "\n",
        "\n",
        "def plot_loss_history(loss_history, other_loss_history = []):\n",
        "    plt.plot(range(1, len(loss_history) + 1), loss_history)\n",
        "    if other_loss_history != []:\n",
        "        plt.plot(range(1, len(other_loss_history) + 1), other_loss_history)\n",
        "    plt.show()\n",
        "\n",
        "# len(alphabets) * max_length * hidden_size + hidden_size * len(languages)\n",
        "# 32 * 12 * 64 + 64 * 18 = 25000\n",
        "#\n",
        "class FeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(len(alphabets) * max_length, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, len(languages))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, max_length, len(alphabets) : 32, 12, 57) -> (32, 12*57)\n",
        "        output = self.layer1(x)\n",
        "        output = F.relu(output)\n",
        "        output = self.layer2(output)\n",
        "        output = F.log_softmax(output, dim = -1)\n",
        "\n",
        "        return output # (batch_size, len(languages) : 32, 18)\n",
        "\n",
        "    def train_model(self, train_data, valid_data, epochs = 100, learning_rate = 0.001, print_every = 1000):\n",
        "        criterion = F.nll_loss\n",
        "        optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
        "\n",
        "        step = 0\n",
        "        train_loss_history = []\n",
        "        valid_loss_history = []\n",
        "\n",
        "        train_log = {}\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for x, y in train_data:\n",
        "                step += 1\n",
        "                y_pred = self(x)\n",
        "                loss = criterion(y_pred, y)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                mean_loss = torch.mean(loss).item()\n",
        "\n",
        "                if step % print_every == 0 or step == 1:\n",
        "                    train_loss_history.append(mean_loss)\n",
        "                    valid_loss, valid_acc = self.evaluate(valid_data)\n",
        "                    valid_loss_history.append(valid_loss)\n",
        "                    print(f'[Epoch {epoch}, Step {step}] train loss: {mean_loss}, valid loss: {valid_loss}, valid_acc: {valid_acc}')\n",
        "                    torch.save(self, f'checkpoints/feedforward_{step}.chkpts')\n",
        "                    print(f'saved model to checkpoints/feedforward_{step}.chkpts')\n",
        "                    train_log[f'checkpoints/feedforward_{step}.chkpts'] = [valid_loss, valid_acc]\n",
        "\n",
        "        pickle.dump(train_log, open('checkpoints/train_log.dict', 'wb+'))\n",
        "\n",
        "        return train_loss_history, valid_loss_history\n",
        "\n",
        "    def evaluate(self, data):\n",
        "        self.eval()\n",
        "        criterion = F.nll_loss\n",
        "\n",
        "        correct, total = 0, 0\n",
        "        loss_list = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in data:\n",
        "                y_pred = self(x)\n",
        "                loss = criterion(y_pred, y)\n",
        "                loss_list.append(torch.mean(loss).item())\n",
        "                correct += torch.sum((torch.argmax(y_pred, dim = 1) == y).float())\n",
        "                total += y.size(0)\n",
        "            return sum(loss_list) / len(loss_list), correct / total\n",
        "\n",
        "train_data, valid_data, test_data = modify_dataset_for_ffn(dataset)\n",
        "\n",
        "model = FeedForwardNetwork(32)\n",
        "loss, acc = model.evaluate(train_data)\n",
        "\n",
        "train_loss_history, valid_loss_history = model.train_model(train_data, valid_data)\n",
        "\n",
        "plot_loss_history(train_loss_history, valid_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'checkpoints/train_log.dict'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m     path_to_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(lst, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x:x[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(path_to_model)\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n",
            "Cell \u001b[1;32mIn[10], line 2\u001b[0m, in \u001b[0;36mfind_best_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_best_model\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     train_log \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints/train_log.dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m     lst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m train_log\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoints/train_log.dict'"
          ]
        }
      ],
      "source": [
        "\n",
        "def find_best_model():\n",
        "    train_log = pickle.load(open('checkpoints/train_log.dict', 'rb'))\n",
        "    lst = []\n",
        "\n",
        "    for k, v in train_log.items():\n",
        "        lst.append((k, v))\n",
        "\n",
        "    path_to_model = max(lst, key = lambda x:x[1][1])[0]\n",
        "\n",
        "    return torch.load(path_to_model)\n",
        "\n",
        "model = find_best_model()\n",
        "model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'languages' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m                 total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     78\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(loss_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loss_list), correct \u001b[38;5;241m/\u001b[39m total\n\u001b[1;32m---> 80\u001b[0m rnn \u001b[38;5;241m=\u001b[39m \u001b[43mRecurrentNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m train_loss_history, valid_loss_history \u001b[38;5;241m=\u001b[39m rnn\u001b[38;5;241m.\u001b[39mtrain_model(train_dataset, valid_dataset)\n\u001b[0;32m     83\u001b[0m plot_loss_history(train_loss_history, valid_loss_history)\n",
            "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36mRecurrentNeuralNetwork.__init__\u001b[1;34m(self, hidden_size, batch_first)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2h \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(hidden_size, hidden_size)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi2h \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mlen\u001b[39m(alphabets), hidden_size)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2o \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(hidden_size, \u001b[38;5;28mlen\u001b[39m(\u001b[43mlanguages\u001b[49m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m hidden_size\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;241m=\u001b[39m batch_first\n",
            "\u001b[1;31mNameError\u001b[0m: name 'languages' is not defined"
          ]
        }
      ],
      "source": [
        "class RecurrentNeuralNetwork(nn.Module):\n",
        "    def __init__(self, hidden_size, batch_first = True):\n",
        "        super(RecurrentNeuralNetwork, self).__init__()\n",
        "        self.i2h = nn.Linear(len(alphabets), hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, len(languages))\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x: (batch_size, max_length, len(alphabets))\n",
        "        hidden = F.tanh(self.i2h(x) + self.h2h(hidden)) # hidden: (batch_size, hidden_size)\n",
        "        if self.batch_first:\n",
        "            output = self.h2o(hidden)\n",
        "            output = F.log_softmax(output, dim = -1)\n",
        "        else:\n",
        "            output = F.log_softmax(self.h2o(hidden), dim = 0)\n",
        "        # output.shape: batch_size, output_size\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.hidden_size)\n",
        "\n",
        "    def train_model(self, train_data, valid_data, epochs = 100, learning_rate = 0.001, print_every = 1000):\n",
        "        criterion = F.nll_loss\n",
        "        optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
        "\n",
        "        step = 0\n",
        "        train_loss_history = []\n",
        "        valid_loss_history = []\n",
        "        for epoch in range(epochs):\n",
        "            for x, y in train_data:\n",
        "                step += 1\n",
        "                # x: (batch_size, max_length, len(alphabets))\n",
        "                if self.batch_first:\n",
        "                    x = x.transpose(0, 1)\n",
        "                # x: (max_length, batch_size, len(alphabets))\n",
        "                hidden = self.init_hidden()\n",
        "                for char in x:\n",
        "                    output, hidden = self(char, hidden)\n",
        "                loss = criterion(output, y)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                mean_loss = torch.mean(loss).item()\n",
        "\n",
        "                if step % print_every == 0 or step == 1:\n",
        "                    train_loss_history.append(mean_loss)\n",
        "                    valid_loss, valid_acc = self.evaluate(valid_data)\n",
        "                    valid_loss_history.append(valid_loss)\n",
        "                    print(f'[Epoch {epoch}, Step {step}] train loss: {mean_loss}, valid loss: {valid_loss}, valid_acc: {valid_acc}')\n",
        "\n",
        "        return train_loss_history, valid_loss_history\n",
        "\n",
        "    def evaluate(self, data):\n",
        "        self.eval()\n",
        "        criterion = F.nll_loss\n",
        "\n",
        "        correct, total = 0, 0\n",
        "        loss_list = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in data:\n",
        "                # x: (batch_size, max_length, len(alphabets))\n",
        "                if self.batch_first:\n",
        "                    x = x.transpose(0, 1)\n",
        "                # x: (max_length, batch_size, len(alphabets))\n",
        "                hidden = self.init_hidden()\n",
        "                for char in x:\n",
        "                    output, hidden = self(char, hidden)\n",
        "                loss = criterion(output, y)\n",
        "\n",
        "                loss_list.append(torch.mean(loss).item())\n",
        "                correct += torch.sum((torch.argmax(output, dim = 1) == y).float())\n",
        "                total += y.size(0)\n",
        "            return sum(loss_list) / len(loss_list), correct / total\n",
        "\n",
        "rnn = RecurrentNeuralNetwork(128)\n",
        "train_loss_history, valid_loss_history = rnn.train_model(train_dataset, valid_dataset)\n",
        "\n",
        "plot_loss_history(train_loss_history, valid_loss_history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
